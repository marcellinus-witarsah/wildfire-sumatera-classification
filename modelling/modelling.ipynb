{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Image Generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling CNN\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Dropout, Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Input, Flatten, BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\wildfire-sumatera-dataset already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-jpeg already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\sentinel-2 already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\landsat-8 already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-jpeg\\sentinel-2 already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-jpeg\\landsat-8 already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\landsat-8\\prefire already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\landsat-8\\postfire already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\sentinel-2\\prefire already exist\n",
      "D:\\wildfire-sumatera-dataset\\wildfire-sumatera-geotiff\\sentinel-2\\postfire already exist\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../\")\n",
    "import data_paths as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "SEED = RANDOM_STATE\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNEL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landsat-8\n",
    "landsat_df = pd.read_csv(dp.METADATA_LANDSAT_8_FILE_PATH)\n",
    "landsat_df_backup = landsat_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert column 'class' type to string\n",
    "landsat_df['class'] = landsat_df['class'].astype(str)\n",
    "# filter image that is in a good condition\n",
    "landsat_df = landsat_df[landsat_df['image_condition'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data for testing and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliting based on class\n",
    "X_train, X_test, _, _, = train_test_split(\n",
    "    landsat_df.index, \n",
    "    landsat_df['class'], \n",
    "    stratify = landsat_df['class'],\n",
    "    test_size = 0.2,\n",
    "    random_state = RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = landsat_df.loc[X_train]\n",
    "test_df = landsat_df.loc[X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class quantity in train df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    3911\n",
       "2    1282\n",
       "0    1075\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class quantity in test df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    978\n",
       "2    321\n",
       "0    269\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Class quantity in train df')\n",
    "display(train_df['class'].value_counts())\n",
    "print('Class quantity in test df')\n",
    "display(test_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator (Image Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range= 0.1,\n",
    "    shear_range= 0.1,\n",
    "    rescale= 1./255,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5015 validated image filenames belonging to 3 classes.\n",
      "Found 1253 validated image filenames belonging to 3 classes.\n",
      "Found 1568 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Applying Generator by using data from dataframe\n",
    "train_data = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    directory = dp.LANDSAT_8_JPEG_FOLDER_PATH,\n",
    "    x_col = 'file_paths_jpeg',\n",
    "    y_col = 'class',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    target_size = (WIDTH,HEIGHT),\n",
    "    subset = \"training\",\n",
    "    class_mode = \"categorical\",\n",
    ")\n",
    "\n",
    "validation_data = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    directory = dp.LANDSAT_8_JPEG_FOLDER_PATH,\n",
    "    x_col = 'file_paths_jpeg',\n",
    "    y_col = 'class',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = SEED,\n",
    "    target_size = (WIDTH,HEIGHT),\n",
    "    subset = \"validation\",\n",
    "    class_mode = \"categorical\",\n",
    ")\n",
    "\n",
    "test_data = test_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    directory = dp.LANDSAT_8_JPEG_FOLDER_PATH,\n",
    "    x_col = 'file_paths_jpeg',\n",
    "    y_col = 'class',\n",
    "    batch_size = len(test_df.index),\n",
    "    seed = SEED,\n",
    "    target_size = (WIDTH,HEIGHT),\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Prototype version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "\n",
    "def get_model_ver_1(input_shape):\n",
    "    # Create Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolution 2D Layer with kernel size 3x3 (filters=32)\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, input_shape=input_shape))\n",
    "    # Activation Layer ReLu function\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Convolution 2D Layer with kernel size 3x3 (filters=64)\n",
    "    model.add(Conv2D(filters=64, kernel_size=3))\n",
    "    # Activation layer ReLu function\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling layer (2D) with pool size of 2x2 (default), strides=(2,2)\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    \n",
    "    # Convolution 2D Layer with kernel size 3x3 (filters=128)\n",
    "    model.add(Conv2D(filters=128, kernel_size=3))\n",
    "    # Activation layer ReLu function\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling layer (2D) with pool size of 2x2 (default), strides=(2,2)\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    \n",
    "    # Flatten layer\n",
    "    model.add(Flatten())\n",
    "    # Fully Connected Layer\n",
    "    model.add(Dense(256))\n",
    "    # Drop Out Layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output model (multiclass)\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    # Activation layer using Sigmoid Function for Logistic Regression\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device -> /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is detected and ready to be used by tensorflow for neural network training process\n",
    "if tf.test.gpu_device_name(): \n",
    "    print(f\"Default GPU Device -> {tf.test.gpu_device_name()}\")\n",
    "\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (256, 256, 3)\n",
    "model = get_model_ver_1(INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Device and Free Memory from GPU\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = get_model_ver_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traditional_cnn_softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18796/2522283573.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                              verbose=2)]\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m traditional_cnn_softmax.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     metrics=['accuracy', 'precision', 'recall'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'traditional_cnn_softmax' is not defined"
     ]
    }
   ],
   "source": [
    "callbacks_softmax = [\n",
    "    EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 2),\n",
    "    ModelCheckpoint(\n",
    "        filepath = './traditional_cnn_multiclass_softmax.h5', \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True,\n",
    "        mode = 'min', \n",
    "        verbose = 2,\n",
    "    )\n",
    "]\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history_softmax = model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=train_data.samples//BATCH_SIZE,\n",
    "    validation_steps=valid_data.samples//BATCH_SIZE,\n",
    "    workers=8,\n",
    "    callbacks=callbacks_softmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(3, size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 0]\n",
      "[0 1 2 1 1 1 1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "y_pred = [\n",
    "    [0.1, 0.5, 0.4],\n",
    "    [0, 0.3, 0.7],\n",
    "    [1, 0, 0],\n",
    "    [0.2, 0.6, 0.2],\n",
    "    [0.1, 0.6, 0.2],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones_like(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wildfire-indonesia)",
   "language": "python",
   "name": "wildfire-indonesia-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
